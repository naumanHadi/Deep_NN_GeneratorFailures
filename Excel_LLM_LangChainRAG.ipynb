{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOwcnHhPh9BpIoLQ6YSuBAj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "88a192397023449bb23bd5c3494a425e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d3be8fc49404578a61b0a51ef93d76f",
              "IPY_MODEL_b1f7241f89194db4a04bea24dc2c4eee",
              "IPY_MODEL_91fa18202a1f44a7b0d573e6794c8b87"
            ],
            "layout": "IPY_MODEL_d9e38b845f144ffd85c5a8cc003deb45"
          }
        },
        "5d3be8fc49404578a61b0a51ef93d76f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57e1fa2a1ab04bea910db879c7f64f7a",
            "placeholder": "​",
            "style": "IPY_MODEL_09755cf24e1443cca3ec65b0b81a9089",
            "value": "Embedding &amp; adding (docs): 100%"
          }
        },
        "b1f7241f89194db4a04bea24dc2c4eee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e33659ec70bd485b9071902cec6f33b7",
            "max": 12956,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_75bee534ea6f4c288fe56d46d5f16573",
            "value": 12956
          }
        },
        "91fa18202a1f44a7b0d573e6794c8b87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66dc3d58131c4df18cfd275b827df496",
            "placeholder": "​",
            "style": "IPY_MODEL_d597ec7450884044a3d4ecbe6810f180",
            "value": " 12956/12956 [05:36&lt;00:00, 37.57doc/s]"
          }
        },
        "d9e38b845f144ffd85c5a8cc003deb45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "57e1fa2a1ab04bea910db879c7f64f7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09755cf24e1443cca3ec65b0b81a9089": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e33659ec70bd485b9071902cec6f33b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75bee534ea6f4c288fe56d46d5f16573": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "66dc3d58131c4df18cfd275b827df496": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d597ec7450884044a3d4ecbe6810f180": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0d19ee8ce2e42e5a3dc098c0ba9a385": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a6cd284798af4c6893b13759b66f88f4",
              "IPY_MODEL_4190288fd57f411692c1e28daa0891ab",
              "IPY_MODEL_a76e216b77f54d7fa26acb91ebadc556"
            ],
            "layout": "IPY_MODEL_20f1d619bd18413487ff3bbea49da6e8"
          }
        },
        "a6cd284798af4c6893b13759b66f88f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_081f0f56b9804e3a833ce30f81c55e33",
            "placeholder": "​",
            "style": "IPY_MODEL_fe4ff68be2fd4b90b5f73914372e67a8",
            "value": "Embedding &amp; adding (tokens): 100%"
          }
        },
        "4190288fd57f411692c1e28daa0891ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f044b7999f6143e888e4f416f4078a81",
            "max": 1399669,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_90b3bde29e804f8c87a5b94688293267",
            "value": 1399669
          }
        },
        "a76e216b77f54d7fa26acb91ebadc556": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b23c765dd08f43df902bb68ac4bd92a4",
            "placeholder": "​",
            "style": "IPY_MODEL_eab624ddf3774a1180047ba44f6628b9",
            "value": " 1399669/1399669 [05:36&lt;00:00, 3581.53tok/s]"
          }
        },
        "20f1d619bd18413487ff3bbea49da6e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "081f0f56b9804e3a833ce30f81c55e33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe4ff68be2fd4b90b5f73914372e67a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f044b7999f6143e888e4f416f4078a81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90b3bde29e804f8c87a5b94688293267": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b23c765dd08f43df902bb68ac4bd92a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eab624ddf3774a1180047ba44f6628b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naumanHadi/Deep_NN_GeneratorFailures/blob/main/Excel_LLM_LangChainRAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_jDmI5qrIcMo",
        "outputId": "c853cb42-0dd4-4c79-841b-e333c520e1fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.6/19.6 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.6/201.6 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip -q install langchain langchain-community chromadb sentence-transformers openpyxl tiktoken gradio\n",
        "\n",
        "import os, glob, pandas as pd, numpy as np\n",
        "from langchain_community.document_loaders import DataFrameLoader\n",
        "from langchain.docstore.document import Document\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.schema import BaseRetriever\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "import openai\n",
        "from google.colab import userdata\n",
        "import os, glob,re\n",
        "import pandas as pd\n",
        "from diffusers import DiffusionPipeline\n",
        "from transformers import pipeline\n",
        "from datasets import load_dataset\n",
        "import soundfile as sf\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "# Retrieval + Memory + Chains\n",
        "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
        "from langchain.memory import ConversationBufferMemory\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJJmasVqOVo7",
        "outputId": "61d4f65d-6ab8-440c-f0d8-8b9763db2661"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_excel(\"/content/drive/MyDrive/Python_Course/Allagi/Combined_Violations.xlsx\")\n",
        "df.info()"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpC_KOSC8Yr4",
        "outputId": "472181fd-07c4-4b1f-beff-d6fd02c15386"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 12898 entries, 0 to 12897\n",
            "Data columns (total 91 columns):\n",
            " #   Column                                                                                     Non-Null Count  Dtype         \n",
            "---  ------                                                                                     --------------  -----         \n",
            " 0   ID                                                                                         12898 non-null  int64         \n",
            " 1   Usid                                                                                       12898 non-null  int64         \n",
            " 2   Quad                                                                                       12898 non-null  int64         \n",
            " 3   Region                                                                                     12898 non-null  object        \n",
            " 4   Market                                                                                     12898 non-null  object        \n",
            " 5   SubMarket                                                                                  12898 non-null  object        \n",
            " 6   EventName                                                                                  12897 non-null  object        \n",
            " 7   CXStart                                                                                    12898 non-null  datetime64[ns]\n",
            " 8   CutoverDate                                                                                12898 non-null  datetime64[ns]\n",
            " 9   SwapType                                                                                   12898 non-null  object        \n",
            " 10  Completed                                                                                  12898 non-null  bool          \n",
            " 11  ClosedOut                                                                                  10551 non-null  object        \n",
            " 12  FullOutage                                                                                 12898 non-null  float64       \n",
            " 13  AvgPartialOutage                                                                           12898 non-null  float64       \n",
            " 14  BrokenRets                                                                                 12898 non-null  int64         \n",
            " 15  FixedRets                                                                                  12898 non-null  int64         \n",
            " 16  OptoApproveDate                                                                            8016 non-null   datetime64[ns]\n",
            " 17  SpectrumDelta                                                                              12898 non-null  int64         \n",
            " 18  CivilSupplier                                                                              12864 non-null  object        \n",
            " 19  SiteAcqSupplier                                                                            12822 non-null  object        \n",
            " 20  ErcNode                                                                                    12898 non-null  object        \n",
            " 21  INTPIMCount                                                                                8808 non-null   float64       \n",
            " 22  INTPIMSummary                                                                              8869 non-null   object        \n",
            " 23  PIMTest                                                                                    8869 non-null   datetime64[ns]\n",
            " 24  SSDStatus                                                                                  8130 non-null   object        \n",
            " 25  SSDUploadDate                                                                              8130 non-null   datetime64[ns]\n",
            " 26  PreAT&T30DAvg                                                                              12510 non-null  float64       \n",
            " 27  PostAT&T30DAvg                                                                             10594 non-null  float64       \n",
            " 28  PreFNET30DAvg                                                                              12510 non-null  float64       \n",
            " 29  PostFNET30DAvg                                                                             10594 non-null  float64       \n",
            " 30  PreIoT30DAvg                                                                               12510 non-null  float64       \n",
            " 31  PostIoT30DAvg                                                                              10594 non-null  float64       \n",
            " 32  PreRoaming30DAvg                                                                           12510 non-null  float64       \n",
            " 33  PostRoaming30DAvg                                                                          10594 non-null  float64       \n",
            " 34  OptoSubmitDate                                                                             8409 non-null   datetime64[ns]\n",
            " 35  Opto_Ready_5640T                                                                           8395 non-null   datetime64[ns]\n",
            " 36  Swap Status (Boolean)                                                                      12898 non-null  bool          \n",
            " 37  Delta New Unique Users                                                                     10353 non-null  float64       \n",
            " 38  Delta New User Flag ( Z Value)                                                             10353 non-null  float64       \n",
            " 39  New User (Reason)                                                                          9483 non-null   object        \n",
            " 40   SUMIDX LTE Index                                                                          5613 non-null   float64       \n",
            " 41  CDR Retainability Index                                                                    5613 non-null   float64       \n",
            " 42  CDR Accessibility Index                                                                    5613 non-null   float64       \n",
            " 43  Flag LTE                                                                                   12898 non-null  int64         \n",
            " 44  Flag CDR                                                                                   12898 non-null  int64         \n",
            " 45  Aging ( Since Cutover)                                                                     10974 non-null  float64       \n",
            " 46  RET ( Quantum DCR)                                                                         5613 non-null   float64       \n",
            " 47  RET (Weights Z_Val DCR)                                                                    5613 non-null   float64       \n",
            " 48  Worst Offenders                                                                            12898 non-null  int64         \n",
            " 49  Flag2 - Ready To Close (RTC)                                                               9434 non-null   float64       \n",
            " 50  Pending Handover Status (Flag1)                                                            12898 non-null  object        \n",
            " 51  True Handover Status                                                                       10063 non-null  object        \n",
            " 52  SSV Hold ( Removal) Date                                                                   2579 non-null   datetime64[ns]\n",
            " 53  Actual 5640T                                                                               10369 non-null  datetime64[ns]\n",
            " 54  True Handover Dates                                                                        9422 non-null   datetime64[ns]\n",
            " 55  True Handover Aging                                                                        9434 non-null   float64       \n",
            " 56  Aging Optimization Reports                                                                 329 non-null    float64       \n",
            " 57  Total Cutover Sites Filter Last 30 Days                                                    12898 non-null  object        \n",
            " 58  Worst Offender - Rolling 30 Days                                                           12898 non-null  object        \n",
            " 59  Max of EUCELL Downtime Manual                                                              5613 non-null   float64       \n",
            " 60  Flag3 ( DowtimeAlert)                                                                      1850 non-null   object        \n",
            " 61  5G Traffic                                                                                 5613 non-null   float64       \n",
            " 62  5G  Site True Flag                                                                         2861 non-null   object        \n",
            " 63  Staggered Launch (Priority))                                                               0 non-null      float64       \n",
            " 64  5G Traffic Flag                                                                            7850 non-null   float64       \n",
            " 65  Opto 21 Days Cycle                                                                         12898 non-null  object        \n",
            " 66  Partial Outage Flag                                                                        12898 non-null  object        \n",
            " 67  Cutover to Handover Time                                                                   9418 non-null   float64       \n",
            " 68  Delayed HO Flag                                                                            12898 non-null  object        \n",
            " 69  Auto Ticketing ( Extended Partial Outage > 100 , Performance Issues, 5G Staggered Launch)  9 non-null      object        \n",
            " 70  SSV Hold Flag                                                                              12898 non-null  object        \n",
            " 71  TimetoHandover (TTH)                                                                       9422 non-null   float64       \n",
            " 72  Turf Vendor Additional Description/Comments                                                5464 non-null   object        \n",
            " 73  Pending HO Reasons (TV/Market PM)                                                          2351 non-null   object        \n",
            " 74  SSV Held Up Reasons - Ericsson RF                                                          292 non-null    object        \n",
            " 75  SSV Held Up Reasons - Ericsson RF ( More Details)                                          292 non-null    object        \n",
            " 76  site_id_lte                                                                                12884 non-null  object        \n",
            " 77  fa_location                                                                                12884 non-null  float64       \n",
            " 78  E/// Verification Status                                                                   282 non-null    object        \n",
            " 79  pm_2                                                                                       12884 non-null  object        \n",
            " 80  Turfvendor Status (Clear / No Clear)                                                       523 non-null    object        \n",
            " 81  Day 0 Failures                                                                             2579 non-null   float64       \n",
            " 82  Dealyed HO -Bucketization                                                                  364 non-null    object        \n",
            " 83  SSV ON Hold Date                                                                           2579 non-null   datetime64[ns]\n",
            " 84  Outages By Days                                                                            10973 non-null  object        \n",
            " 85  NEA Range                                                                                  39 non-null     object        \n",
            " 86  NEA_Violation                                                                              39 non-null     object        \n",
            " 87   Age                                                                                       39 non-null     float64       \n",
            " 88  BBU Range                                                                                  146 non-null    object        \n",
            " 89  BBU_Violation                                                                              146 non-null    object        \n",
            " 90  Age(days)                                                                                  146 non-null    float64       \n",
            "dtypes: bool(2), datetime64[ns](11), float64(32), int64(9), object(37)\n",
            "memory usage: 8.8+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading all the data from Google Drive (Combined Violations)"
      ],
      "metadata": {
        "id": "9D01_SoxKiax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df[\"SSV Held Up Reasons - Ericsson RF ( More Details)\"].head(500)\n",
        "df[\"SSV Held Up Reasons - Ericsson RF\"].head(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "8HndGAcFFgKU",
        "outputId": "24354551-2c39-41d2-fcb1-5e989313b223"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    \n",
              "1    \n",
              "2    \n",
              "3    \n",
              "4    \n",
              "Name: SSV Held Up Reasons - Ericsson RF, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SSV Held Up Reasons - Ericsson RF</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# STEP 2 — Load, Clean, Prepare (NO AUTO-DROP)\n",
        "# =========================\n",
        "\n",
        "# LangChain Document import (compatible with older/newer LC)\n",
        "try:\n",
        "    from langchain_core.documents import Document\n",
        "except Exception:\n",
        "    from langchain.docstore.document import Document\n",
        "\n",
        "import os, re, glob, difflib, unicodedata\n",
        "import pandas as pd\n",
        "\n",
        "# --- Set this ONCE. Can be a single Excel file OR a folder path ---\n",
        "DATA_PATH = \"/content/drive/MyDrive/Python_Course/Allagi/Combined_Violations.xlsx\"  # or folder\n",
        "\n",
        "# --- Build mode ---\n",
        "MODE    = \"ROW_MODE\"   # \"ROW_MODE\" now; switch to \"PROFILE_MODE\" if you later have multiple rows per Usid\n",
        "KEY_COL = \"Usid\"       # used only in PROFILE_MODE\n",
        "\n",
        "# --- Your intended text-heavy columns (as you named them) ---\n",
        "WANT_TEXT_COLS_RAW = [\n",
        "    \"Turf Vendor Additional Description/Comments\",\n",
        "    \"Pending HO Reasons (TV/Market PM)\",\n",
        "    \"SSV Held Up Reasons - Ericsson RF\",\n",
        "    \"SSV Held Up Reasons - Ericsson RF ( More Details)\",\n",
        "    # Optionally include if sentence-like:\n",
        "    # \"True Handover Status\",\n",
        "]\n",
        "\n",
        "# --- Metadata to keep (filtering; not embedded) ---\n",
        "META_COLS = [\n",
        "    \"ID\", \"Usid\", \"Quad\", \"Region\", \"Market\", \"SubMarket\",\n",
        "    \"CivilSupplier\", \"SwapType\", \"Completed\", \"ClosedOut\",\n",
        "    \"CutoverDate\", \"SSV Hold ( Removal) Date\",\n",
        "    \"True Handover Status\", \"__file\", \"__sheet\",\n",
        "]\n",
        "\n",
        "# --- Columns you NEVER want used in RAG (excluded from embeddings & metadata) ---\n",
        "RAG_EXCLUDE = {\n",
        "    \"Flag2 - Ready To Close (RTC)\",\n",
        "    \"Pending Handover Status (Flag1)\",\n",
        "    \"Aging Optimization Reports\",\n",
        "    \"Flag3 ( DowtimeAlert)\",\n",
        "    \"Flag3 (DowntimeAlert)\",\n",
        "    \"5G Traffic\",\n",
        "    \"5G  Site True Flag\",\n",
        "    \"Staggered Launch (Priority))\",\n",
        "    \"Staggered Launch (Priority)\",\n",
        "    \"5G Traffic Flag\",\n",
        "    \"Delayed HO Flag\",\n",
        "    \"Auto Ticketing ( Extended Partial Outage > 100 , Performance Issues, 5G Staggered Launch)\",\n",
        "}\n",
        "\n",
        "# --- Optional: explicit white/black lists (kept here but not needed if you don't want any drop) ---\n",
        "KEEP_COLS = []   # e.g., [\"ID\",\"Usid\",\"Region\",\"Market\"]\n",
        "DROP_COLS = []   # e.g., [\"Unnamed: 0\"]\n",
        "\n",
        "# --- Header normalization / renames ---\n",
        "RENAME_MAP = {\n",
        "    \"Staggered Launch (Priority))\": \"Staggered Launch (Priority)\",\n",
        "    \"Flag3 ( DowtimeAlert)\": \"Flag3 (DowntimeAlert)\",\n",
        "    \"True Handover Status \": \"True Handover Status\",  # trim trailing space\n",
        "    \"SSV Hold Flag \": \"SSV Hold Flag\"\n",
        "}\n",
        "\n",
        "def _clean_headers(cols):\n",
        "    seen = {}\n",
        "    new_cols = []\n",
        "    for c in cols:\n",
        "        nc = re.sub(r\"\\s+\", \" \", str(c or \"\")).strip()\n",
        "        if nc.startswith(\"Unnamed\"):\n",
        "            nc = \"Unnamed\"\n",
        "        nc = RENAME_MAP.get(nc, nc)\n",
        "        if nc in seen:\n",
        "            seen[nc] += 1\n",
        "            nc = f\"{nc}__{seen[nc]}\"\n",
        "        else:\n",
        "            seen[nc] = 1\n",
        "        new_cols.append(nc)\n",
        "    return new_cols\n",
        "\n",
        "def _read_excels(path):\n",
        "    frames = []\n",
        "    if os.path.isfile(path) and path.lower().endswith((\".xlsx\", \".xls\")):\n",
        "        file_list = [path]\n",
        "    else:\n",
        "        file_list = glob.glob(f\"{path}/**/*.xlsx\", recursive=True) + \\\n",
        "                    glob.glob(f\"{path}/**/*.xls\", recursive=True)\n",
        "    for f in file_list:\n",
        "        try:\n",
        "            xls = pd.ExcelFile(f)\n",
        "            for sheet in xls.sheet_names:\n",
        "                df = pd.read_excel(f, sheet_name=sheet, dtype=str)\n",
        "                df[\"__file\"] = os.path.basename(f)\n",
        "                df[\"__sheet\"] = sheet\n",
        "                frames.append(df)\n",
        "        except Exception as e:\n",
        "            print(\"Skipping:\", f, \"->\", e)\n",
        "    return pd.concat(frames, ignore_index=True) if frames else pd.DataFrame()\n",
        "\n",
        "# --- 2.1 Load ---\n",
        "raw = _read_excels(DATA_PATH)\n",
        "print(\"Raw shape:\", raw.shape)\n",
        "\n",
        "# --- 2.2 Clean headers ---\n",
        "df = raw.copy()\n",
        "df.columns = _clean_headers(df.columns)\n",
        "\n",
        "# --- 2.3 Drop explicit bad columns ONLY (no auto-drop anywhere else) ---\n",
        "if DROP_COLS:\n",
        "    df = df.drop(columns=[c for c in DROP_COLS if c in df.columns], errors=\"ignore\")\n",
        "\n",
        "# --- 2.4 KEEP_COLS whitelist (optional) ---\n",
        "if KEEP_COLS:\n",
        "    keep = [c for c in KEEP_COLS if c in df.columns]\n",
        "    for sys_tag in [\"__file\", \"__sheet\"]:\n",
        "        if sys_tag in df.columns and sys_tag not in keep:\n",
        "            keep.append(sys_tag)\n",
        "    if keep:\n",
        "        df = df[keep]\n",
        "\n",
        "# --- 2.5 Fill & normalize whitespace (no deprecated applymap) ---\n",
        "df = df.fillna(\"\")\n",
        "df = df.apply(lambda s: (\n",
        "    s.astype(str)\n",
        "     .str.replace(r\"\\s+\", \" \", regex=True)\n",
        "     .str.strip()\n",
        "))\n",
        "\n",
        "# --- 2.6 Resolve desired TEXT_COLS against cleaned headers (fuzzy-safe) ---\n",
        "def _canon(s: str) -> str:\n",
        "    s = unicodedata.normalize(\"NFKC\", s)\n",
        "    s = s.lower().strip()\n",
        "    s = re.sub(r\"\\s+\", \" \", s)\n",
        "    s = re.sub(r\"[\\(\\)\\-_/]+\", \" \", s)   # drop common separators\n",
        "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
        "    return s\n",
        "\n",
        "canon_to_real = {_canon(c): c for c in df.columns}\n",
        "canon_cols = list(canon_to_real.keys())\n",
        "\n",
        "resolved_text_cols = []\n",
        "mapping_report = []\n",
        "for want in WANT_TEXT_COLS_RAW:\n",
        "    want_key = _canon(want)\n",
        "    if want_key in canon_to_real:\n",
        "        real = canon_to_real[want_key]\n",
        "        resolved_text_cols.append(real)\n",
        "        mapping_report.append(f\"✔ '{want}' → '{real}'\")\n",
        "    else:\n",
        "        close = difflib.get_close_matches(want_key, canon_cols, n=1, cutoff=0.65)\n",
        "        if close:\n",
        "            real = canon_to_real[close[0]]\n",
        "            resolved_text_cols.append(real)\n",
        "            mapping_report.append(f\"~ '{want}' → '{real}' (fuzzy)\")\n",
        "        else:\n",
        "            mapping_report.append(f\"✘ '{want}' → NOT FOUND\")\n",
        "\n",
        "print(\"\\n\".join(mapping_report))\n",
        "\n",
        "# keep only valid, non-excluded text cols\n",
        "TEXT_COLS = [c for c in resolved_text_cols if c in df.columns and c not in RAG_EXCLUDE and c not in {\"__file\",\"__sheet\"}]\n",
        "\n",
        "# If all chosen text cols are empty strings for all rows, we still keep them (per your \"don't drop\")\n",
        "# but we warn so you know why some rows may produce no text.\n",
        "def _nonempty_ratio(col):\n",
        "    return (df[col].astype(str).str.strip() != \"\").mean() if col in df.columns else 0.0\n",
        "\n",
        "for c in TEXT_COLS:\n",
        "    ratio = _nonempty_ratio(c)\n",
        "    if ratio == 0.0:\n",
        "        print(f\"⚠ Column '{c}' appears entirely empty after cleaning; docs from those rows may be blank.\")\n",
        "\n",
        "# Validate metadata list against df + exclusions\n",
        "META_COLS = [c for c in META_COLS if c in df.columns and c not in RAG_EXCLUDE]\n",
        "\n",
        "def _row_to_narrative(row_dict, text_cols):\n",
        "    \"\"\"Turn selected text columns into a compact narrative with section headers; skip blanks.\"\"\"\n",
        "    parts = []\n",
        "    for c in text_cols:\n",
        "        val = str(row_dict.get(c, \"\")).strip()\n",
        "        if val and val not in {\"-\", \"N/A\", \"NA\"}:\n",
        "            parts.append(f\"## {c}\\n{val}\")\n",
        "    return \"\\n\\n\".join(parts)\n",
        "\n",
        "# --- 2.7 Build documents ---\n",
        "docs = []\n",
        "\n",
        "if MODE == \"ROW_MODE\":\n",
        "    for r in df.itertuples(index=False):\n",
        "        row = r._asdict()\n",
        "        text = _row_to_narrative(row, TEXT_COLS)\n",
        "        if not text:\n",
        "            # keep behavior: if a row has no text in TEXT_COLS, skip building a doc for that row\n",
        "            # (this avoids blank docs in your vector store)\n",
        "            continue\n",
        "        meta = {k: row.get(k, \"\") for k in META_COLS}\n",
        "        meta[\"_doc_id\"] = str(row.get(\"Usid\", \"\")) or str(row.get(\"ID\", \"\"))\n",
        "        docs.append(Document(page_content=text, metadata=meta))\n",
        "\n",
        "elif MODE == \"PROFILE_MODE\":\n",
        "    if KEY_COL not in df.columns:\n",
        "        raise ValueError(f\"PROFILE_MODE requires KEY_COL '{KEY_COL}' in the data.\")\n",
        "    grouped = df.groupby(KEY_COL, dropna=False)\n",
        "    for key_val, g in grouped:\n",
        "        sections = []\n",
        "        for c in TEXT_COLS:\n",
        "            vals = [v for v in g[c].astype(str).tolist() if v.strip() and v not in {\"-\", \"N/A\", \"NA\"}]\n",
        "            if not vals:\n",
        "                continue\n",
        "            seen = set()\n",
        "            uniq = [v for v in vals if not (v in seen or seen.add(v))]\n",
        "            sections.append(f\"## {c}\\n\" + \"\\n\\n\".join(uniq))\n",
        "        if not sections:\n",
        "            continue\n",
        "        header = [f\"# Profile — {KEY_COL}: {key_val}\"]\n",
        "        for k in [\"Market\", \"Region\", \"CivilSupplier\", \"True Handover Status\"]:\n",
        "            if k in g.columns:\n",
        "                vals = [v for v in g[k].astype(str).unique().tolist() if v.strip()]\n",
        "                if vals:\n",
        "                    header.append(f\"- {k}: {', '.join(vals[:3])}\")\n",
        "        text = \"\\n\".join(header) + \"\\n\\n\" + \"\\n\\n\".join(sections)\n",
        "        last = g.tail(1).to_dict(orient=\"records\")[0]\n",
        "        meta = {k: last.get(k, \"\") for k in META_COLS}\n",
        "        meta[KEY_COL] = key_val\n",
        "        meta[\"_doc_id\"] = str(key_val)\n",
        "        docs.append(Document(page_content=text, metadata=meta))\n",
        "else:\n",
        "    raise ValueError(\"MODE must be 'ROW_MODE' or 'PROFILE_MODE'\")\n",
        "\n",
        "print(f\"✅ Cleaned shape: {df.shape}\")\n",
        "print(f\"✅ Built {len(docs)} documents\")\n",
        "print(f\"🧾 TEXT_COLS used for embeddings: {TEXT_COLS}\")\n",
        "print(f\"🏷️ Metadata columns (for filters): {META_COLS}\")\n",
        "if docs:\n",
        "    print(\"🔎 Example doc metadata:\", docs[0].metadata)\n",
        "    print(\"🔎 Example doc preview:\\n\", docs[0].page_content[:600], \"...\")\n",
        "else:\n",
        "    print(\"No documents built — verify TEXT_COLS and input data.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55VRkoVIAOM3",
        "outputId": "ad55187f-8486-4dbc-c999-e7946f1a2f7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw shape: (12898, 93)\n",
            "✔ 'Turf Vendor Additional Description/Comments' → 'Turf Vendor Additional Description/Comments'\n",
            "✔ 'Pending HO Reasons (TV/Market PM)' → 'Pending HO Reasons (TV/Market PM)'\n",
            "✔ 'SSV Held Up Reasons - Ericsson RF' → 'SSV Held Up Reasons - Ericsson RF'\n",
            "✔ 'SSV Held Up Reasons - Ericsson RF ( More Details)' → 'SSV Held Up Reasons - Ericsson RF ( More Details)'\n",
            "✅ Cleaned shape: (12898, 93)\n",
            "✅ Built 0 documents\n",
            "🧾 TEXT_COLS used for embeddings: ['Turf Vendor Additional Description/Comments', 'Pending HO Reasons (TV/Market PM)', 'SSV Held Up Reasons - Ericsson RF', 'SSV Held Up Reasons - Ericsson RF ( More Details)']\n",
            "🏷️ Metadata columns (for filters): ['ID', 'Usid', 'Quad', 'Region', 'Market', 'SubMarket', 'CivilSupplier', 'SwapType', 'Completed', 'ClosedOut', 'CutoverDate', 'SSV Hold ( Removal) Date', 'True Handover Status', '__file', '__sheet']\n",
            "No documents built — verify TEXT_COLS and input data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# STEP 2.10 — Build row docs with ID header + safe splitting\n",
        "# =========================\n",
        "# Requires: df, TEXT_COLS, META_COLS from earlier; Document class imported.\n",
        "# Produces: row_docs, split_docs\n",
        "\n",
        "import re\n",
        "from langchain.text_splitter import TokenTextSplitter\n",
        "import tiktoken\n",
        "\n",
        "# --- Config ---\n",
        "INCLUDE_EMPTY_ROWS = True   # <-- keep even rows with no text in TEXT_COLS\n",
        "MAX_ROW_TOKENS     = 2000\n",
        "SPLIT_SIZE         = 700\n",
        "SPLIT_OVERLAP      = 60\n",
        "\n",
        "# What to surface in the header (embed these so numeric lookups work)\n",
        "HEADER_KEYS = [\n",
        "    \"Usid\", \"ID\", \"Region\", \"Market\", \"SubMarket\",\n",
        "    \"True Handover Status\", \"CutoverDate\", \"CivilSupplier\", \"SwapType\",\n",
        "    \"Completed\", \"ClosedOut\"\n",
        "]\n",
        "\n",
        "_MISS = {\"\", \"0\", \"-\", \"na\", \"n/a\", \"none\", \"null\"}\n",
        "def _norm(x: str) -> str:\n",
        "    s = re.sub(r\"\\s+\", \" \", str(x or \"\")).strip()\n",
        "    return \"\" if s.lower() in _MISS else s\n",
        "\n",
        "def _header_block(row_dict: dict) -> str:\n",
        "    parts = []\n",
        "    for k in HEADER_KEYS:\n",
        "        if k in row_dict:\n",
        "            v = _norm(row_dict[k])\n",
        "            if v: parts.append(f\"{k}: {v}\")\n",
        "    # Also ensure canonical numeric tokens exist exactly once\n",
        "    usid = _norm(row_dict.get(\"Usid\", \"\"))\n",
        "    if usid and not any(p.startswith(\"Usid:\") or p.startswith(\"USID:\") for p in parts):\n",
        "        parts.insert(0, f\"USID: {usid}\")\n",
        "    _id = _norm(row_dict.get(\"ID\", \"\"))\n",
        "    if _id and not any(p.startswith(\"ID:\") for p in parts):\n",
        "        parts.insert(1 if usid else 0, f\"ID: {_id}\")\n",
        "    return \"## Keys\\n\" + \" | \".join(parts) if parts else \"## Keys\\n\"\n",
        "\n",
        "def _section(col: str, val: str) -> str:\n",
        "    v = _norm(val)\n",
        "    return f\"## {col}\\n{v}\\n\" if v else \"\"\n",
        "\n",
        "# Build one page_content per row\n",
        "def _row_to_page(row):\n",
        "    r = row.to_dict()\n",
        "    header = _header_block(r)\n",
        "    # sections for your 4 text-heavy columns\n",
        "    body_parts = []\n",
        "    for col in TEXT_COLS:\n",
        "        if col in r:\n",
        "            body_parts.append(_section(col, r[col]))\n",
        "    body = \"\\n\".join([p for p in body_parts if p])\n",
        "    if not body.strip():\n",
        "        if not INCLUDE_EMPTY_ROWS:\n",
        "            return \"\"  # signal to drop this row\n",
        "        body = \"## Notes\\n(No detailed comments available.)\"\n",
        "    return header + \"\\n\\n\" + body\n",
        "\n",
        "# Create one Document per row (with metadata), then split long ones\n",
        "row_docs = []\n",
        "for _, row in df.iterrows():\n",
        "    page = _row_to_page(row)\n",
        "    if not page:   # dropped due to INCLUDE_EMPTY_ROWS=False and no text\n",
        "        continue\n",
        "    md = {k: row[k] for k in META_COLS if k in df.columns}\n",
        "    # ensure retrieval keys exist in metadata too\n",
        "    md[\"_doc_id\"] = md.get(\"Usid\") or md.get(\"ID\") or \"\"\n",
        "    md[\"_chunk_id\"] = \"whole\"\n",
        "    row_docs.append(Document(page_content=page, metadata=md))\n",
        "\n",
        "print(f\"Built {len(row_docs)} row docs (header + sections)\")\n",
        "\n",
        "# --- Conditional split to avoid embedding token errors ---\n",
        "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
        "def ntoks(text: str) -> int: return len(enc.encode(text or \"\"))\n",
        "\n",
        "token_splitter = TokenTextSplitter(chunk_size=SPLIT_SIZE, chunk_overlap=SPLIT_OVERLAP)\n",
        "\n",
        "split_docs = []\n",
        "kept = split_ct = 0\n",
        "for d in row_docs:\n",
        "    if ntoks(d.page_content) <= MAX_ROW_TOKENS:\n",
        "        split_docs.append(d); kept += 1\n",
        "    else:\n",
        "        # optional pre-split by '## ' boundaries so fields stay intact\n",
        "        paragraphs = re.split(r\"\\n(?=## )\", d.page_content)\n",
        "        pre_docs = [type(d)(page_content=p, metadata={**d.metadata, \"_chunk_id\": f\"p{i+1}\"}) for i, p in enumerate(paragraphs) if p.strip()]\n",
        "        chunks = token_splitter.split_documents(pre_docs)\n",
        "        # ensure chunk ids are unique and deterministic\n",
        "        for i, c in enumerate(chunks):\n",
        "            c.metadata[\"_chunk_id\"] = c.metadata.get(\"_chunk_id\", \"whole\") + f\":c{i+1}\"\n",
        "        split_docs.extend(chunks); split_ct += 1\n",
        "\n",
        "print(f\"Rows kept whole: {kept}, rows split: {split_ct}, total chunks: {len(split_docs)}\")\n",
        "\n",
        "# Sanity peek\n",
        "if split_docs:\n",
        "    s = split_docs[0]\n",
        "    print(\"Sample metadata:\", s.metadata)\n",
        "    print(\"Sample content:\\n\", (s.page_content[:400] + \"...\") if len(s.page_content) > 400 else s.page_content)\n",
        "else:\n",
        "    print(\"No documents created; check TEXT_COLS and HEADER_KEYS.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnyyMHf5pNAV",
        "outputId": "d7a00677-7a8b-431f-e1b0-9543b5111aa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built 12898 row docs (header + sections)\n",
            "Rows kept whole: 12892, rows split: 6, total chunks: 12956\n",
            "Sample metadata: {'ID': '12997', 'Usid': '208177', 'Quad': '3', 'Region': 'WEST', 'Market': 'PACIFIC NORTHWEST', 'SubMarket': 'OREGON', 'CivilSupplier': '', 'SwapType': 'Cold', 'Completed': 'False', 'ClosedOut': '', 'CutoverDate': '2025-08-22 00:00:00', 'SSV Hold ( Removal) Date': '', 'True Handover Status': '', '__file': 'Combined_Violations.xlsx', '__sheet': 'Sheet1', '_doc_id': '208177', '_chunk_id': 'whole'}\n",
            "Sample content:\n",
            " ## Keys\n",
            "Usid: 208177 | ID: 12997 | Region: WEST | Market: PACIFIC NORTHWEST | SubMarket: OREGON | CutoverDate: 2025-08-22 00:00:00 | SwapType: Cold | Completed: False\n",
            "\n",
            "## Notes\n",
            "(No detailed comments available.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install -U langchain-community chromadb tiktoken tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtYXqpwvaoIg",
        "outputId": "cf725f71-4af0-4c7b-d90e-1eb8b4d99237"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.0 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# STEP 3 — Embed with OpenAI + add to Chroma (fresh DB, progress bars)\n",
        "# =========================\n",
        "# %pip -q install -U langchain-openai langchain-community chromadb tiktoken tqdm\n",
        "\n",
        "# 3.0 Imports\n",
        "try:\n",
        "    from langchain_openai import OpenAIEmbeddings          # preferred\n",
        "except Exception:\n",
        "    from langchain.embeddings.openai import OpenAIEmbeddings  # legacy\n",
        "\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from tqdm.auto import tqdm\n",
        "import os, shutil, datetime as dt\n",
        "import tiktoken\n",
        "\n",
        "# 3.1 Use today's chunks\n",
        "source_docs = split_docs if \"split_docs\" in globals() and split_docs else docs\n",
        "assert source_docs and len(source_docs) > 0, \"split_docs/docs is empty — run Step 2.10 first.\"\n",
        "\n",
        "# 3.2 API key\n",
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\") or os.environ.get(\"OPENAI_API_KEY\", \"\")\n",
        "assert os.environ.get(\"OPENAI_API_KEY\"), \"Set OPENAI_API_KEY.\"\n",
        "\n",
        "# 3.3 Fresh persist dir + collection\n",
        "excel_folder  = os.path.dirname(DATA_PATH)\n",
        "\n",
        "# ⚠️ Force a brand-new DB folder to avoid 'no such table: tenants'\n",
        "PERSIST_DIR   = os.path.join(excel_folder, \"chroma_db_hdr\")  # new folder name\n",
        "if os.path.exists(PERSIST_DIR):\n",
        "    print(f\"🧹 Removing old DB at {PERSIST_DIR} …\")\n",
        "    shutil.rmtree(PERSIST_DIR)\n",
        "os.makedirs(PERSIST_DIR, exist_ok=True)\n",
        "\n",
        "collection_name = f\"tv_profiles_hdr_{dt.datetime.now():%Y%m%d_%H%M}\"\n",
        "print(f\"📂 Chroma DB: {PERSIST_DIR}\\n🗂️ Collection: {collection_name}\")\n",
        "\n",
        "# 3.4 Embeddings\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")  # or 3-large\n",
        "\n",
        "# 3.5 Create collection (with fallback to /content/ if Drive locks)\n",
        "def open_chroma_or_fallback():\n",
        "    try:\n",
        "        return Chroma(persist_directory=PERSIST_DIR,\n",
        "                      collection_name=collection_name,\n",
        "                      embedding_function=embeddings)\n",
        "    except Exception as e:\n",
        "        print(\"⚠️ Persist init failed, falling back to local runtime:\", e)\n",
        "        fb = f\"/content/chroma_hdr_{dt.datetime.now():%Y%m%d_%H%M%S}\"\n",
        "        os.makedirs(fb, exist_ok=True)\n",
        "        print(\"📦 Using fallback DB at:\", fb)\n",
        "        return Chroma(persist_directory=fb,\n",
        "                      collection_name=collection_name,\n",
        "                      embedding_function=embeddings)\n",
        "\n",
        "chroma_vs = open_chroma_or_fallback()\n",
        "\n",
        "# 3.6 Token-safe batching + progress\n",
        "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
        "MAX_TOKENS_PER_REQUEST = 240_000\n",
        "MAX_DOCS_PER_BATCH     = 64\n",
        "\n",
        "def batch_docs_by_tokens(docs, max_tokens=MAX_TOKENS_PER_REQUEST, max_items=MAX_DOCS_PER_BATCH):\n",
        "    batch, toks = [], 0\n",
        "    for d in docs:\n",
        "        t = len(enc.encode(d.page_content or \"\"))\n",
        "        if t >= max_tokens:\n",
        "            if batch: yield batch; batch, toks = [], 0\n",
        "            yield [d]; continue\n",
        "        if batch and (toks + t > max_tokens or len(batch) >= max_items):\n",
        "            yield batch; batch, toks = [], 0\n",
        "        batch.append(d); toks += t\n",
        "    if batch: yield batch\n",
        "\n",
        "total_docs   = len(source_docs)\n",
        "total_tokens = sum(len(enc.encode(d.page_content or \"\")) for d in source_docs)\n",
        "added = 0\n",
        "\n",
        "with tqdm(total=total_docs,  desc=\"Embedding & adding (docs)\",   unit=\"doc\", dynamic_ncols=True) as p_docs, \\\n",
        "     tqdm(total=total_tokens, desc=\"Embedding & adding (tokens)\", unit=\"tok\", dynamic_ncols=True) as p_toks:\n",
        "    for batch in batch_docs_by_tokens(source_docs):\n",
        "        bdocs = list(batch)\n",
        "        chroma_vs.add_documents(bdocs)\n",
        "        added += len(bdocs)\n",
        "        p_docs.update(len(bdocs))\n",
        "        p_toks.update(sum(len(enc.encode(d.page_content or \"\")) for d in bdocs))\n",
        "\n",
        "print(f\"✅ Added {added} vectors. Total now: {chroma_vs._collection.count()}\")\n",
        "\n",
        "# 3.7 Retriever\n",
        "retriever = chroma_vs.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 8, \"fetch_k\": 32})\n",
        "print(\"✅ Retriever ready.\")\n",
        "\n",
        "# 3.8 Smoke test\n",
        "q = \"Tell me about 59919\"\n",
        "hits = retriever.get_relevant_documents(q)\n",
        "print(\"\\nTop hit metadata:\", hits[0].metadata if hits else \"—\")\n",
        "print(\"Top hit preview:\", hits[0].page_content[:200] + \"...\" if hits else \"—\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396,
          "referenced_widgets": [
            "88a192397023449bb23bd5c3494a425e",
            "5d3be8fc49404578a61b0a51ef93d76f",
            "b1f7241f89194db4a04bea24dc2c4eee",
            "91fa18202a1f44a7b0d573e6794c8b87",
            "d9e38b845f144ffd85c5a8cc003deb45",
            "57e1fa2a1ab04bea910db879c7f64f7a",
            "09755cf24e1443cca3ec65b0b81a9089",
            "e33659ec70bd485b9071902cec6f33b7",
            "75bee534ea6f4c288fe56d46d5f16573",
            "66dc3d58131c4df18cfd275b827df496",
            "d597ec7450884044a3d4ecbe6810f180",
            "f0d19ee8ce2e42e5a3dc098c0ba9a385",
            "a6cd284798af4c6893b13759b66f88f4",
            "4190288fd57f411692c1e28daa0891ab",
            "a76e216b77f54d7fa26acb91ebadc556",
            "20f1d619bd18413487ff3bbea49da6e8",
            "081f0f56b9804e3a833ce30f81c55e33",
            "fe4ff68be2fd4b90b5f73914372e67a8",
            "f044b7999f6143e888e4f416f4078a81",
            "90b3bde29e804f8c87a5b94688293267",
            "b23c765dd08f43df902bb68ac4bd92a4",
            "eab624ddf3774a1180047ba44f6628b9"
          ]
        },
        "id": "ZqVjnY8dr3mX",
        "outputId": "6d902493-a800-4422-9c46-3f21959b3c01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧹 Removing old DB at /content/drive/MyDrive/Python_Course/Allagi/chroma_db_hdr …\n",
            "📂 Chroma DB: /content/drive/MyDrive/Python_Course/Allagi/chroma_db_hdr\n",
            "🗂️ Collection: tv_profiles_hdr_20250813_1539\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-839399258.py:40: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
            "  embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")  # or 3-large\n",
            "/tmp/ipython-input-839399258.py:45: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
            "  return Chroma(persist_directory=PERSIST_DIR,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Embedding & adding (docs):   0%|          | 0/12956 [00:00<?, ?doc/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "88a192397023449bb23bd5c3494a425e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Embedding & adding (tokens):   0%|          | 0/1399669 [00:00<?, ?tok/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f0d19ee8ce2e42e5a3dc098c0ba9a385"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Added 12956 vectors. Total now: 12956\n",
            "✅ Retriever ready.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-839399258.py:97: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  hits = retriever.get_relevant_documents(q)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top hit metadata: {'True Handover Status': '', 'ClosedOut': '', 'Completed': 'False', 'SubMarket': 'PHILADELPHIA', 'ID': '8093', '_doc_id': '299691', '__sheet': 'Sheet1', 'SSV Hold ( Removal) Date': '', 'SwapType': 'Cold', '__file': 'Combined_Violations.xlsx', 'Quad': '3', 'CutoverDate': '2025-08-15 00:00:00', 'Market': 'E. PA/S. NJ/DE', 'CivilSupplier': 'Jacobs', 'Usid': '299691', '_chunk_id': 'whole', 'Region': 'EAST'}\n",
            "Top hit preview: ## Keys\n",
            "Usid: 299691 | ID: 8093 | Region: EAST | Market: E. PA/S. NJ/DE | SubMarket: PHILADELPHIA | CutoverDate: 2025-08-15 00:00:00 | CivilSupplier: Jacobs | SwapType: Cold | Completed: False\n",
            "\n",
            "## Not...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BiQEtyQr0ndW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# STEP 4 — LLM + RAG chains (flexible: one-liner for fields, summary otherwise)\n",
        "# =========================\n",
        "\n",
        "# 4.1 Import ChatOpenAI (new path first; fallback for older stacks)\n",
        "try:\n",
        "    from langchain_openai import ChatOpenAI\n",
        "except Exception:\n",
        "    from langchain.chat_models import ChatOpenAI  # older LangChain\n",
        "\n",
        "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
        "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "# --- ID/USID filter helper (metadata-aware retrieval) ---\n",
        "import re\n",
        "def _build_filter_from_question(q: str):\n",
        "    \"\"\"Extract a USID or ID from the question and build a Chroma filter.\"\"\"\n",
        "    q = str(q)\n",
        "    m = re.search(r'\\b(?:USID\\s*[:#]?\\s*)?(\\d{3,})\\b', q, re.I)  # matches 'USID 59919' or just '59919'\n",
        "    if m: return {\"Usid\": m.group(1)}\n",
        "    m = re.search(r'\\bID\\s*[:#]?\\s*(\\d{3,})\\b', q, re.I)         # matches 'ID 12011'\n",
        "    if m: return {\"ID\": m.group(1)}\n",
        "    return None\n",
        "\n",
        "# 4.2 Pick your LLM\n",
        "LLM_MODEL = \"gpt-4o\"  # or \"gpt-4o-mini\" for cheaper/faster\n",
        "llm = ChatOpenAI(model=LLM_MODEL, temperature=0)\n",
        "\n",
        "# 4.3 Flexible prompt:\n",
        "#     - If the user asks for ONE attribute (Market/Region/SubMarket/CivilSupplier/True Handover Status/CutoverDate/SwapType/Completed/ClosedOut),\n",
        "#       respond EXACTLY \"<Attribute>: <value>\" (no extra words).\n",
        "#     - Otherwise, write a concise narrative (3–6 sentences) that mentions CivilSupplier & True Handover Status,\n",
        "#       and summarizes ONLY:\n",
        "#         • SSV Held Up Reasons – Ericsson RF ( More Details)  (Ericsson comments)\n",
        "#         • Turf Vendor Additional Description/Comments         (Civil supplier comments)\n",
        "#       If both comment fields are missing, say: \"No detailed reasons/comments provided.\"\n",
        "def build_flexible_prompt() -> ChatPromptTemplate:\n",
        "    system = (\n",
        "   \"You are a helpful analyst for the AT&T Allagi telecom deployment project.\\n\"\n",
        "        # Small talk bypass\n",
        "        \"If the user's message is a greeting, acknowledgement, thanks, or farewell \"\n",
        "        \"(e.g., 'hi', 'hello', 'thanks', 'ok', 'bye'), reply briefly and naturally \"\n",
        "        \"WITHOUT using any context.\\n\\n\"\n",
        "\n",
        "        # Grounded RAG behavior\n",
        "        \"Otherwise, answer STRICTLY from the provided context (Excel row profiles). \"\n",
        "        \"If not in the context, reply exactly: \\\"I don't know based on the provided context.\\\" \"\n",
        "        \"Treat 0, '-', 'NA', and empty as missing. Preserve numeric identifiers (USID, ID) verbatim.\\n\\n\"\n",
        "\n",
        "        # One-liner mode for single attribute lookups\n",
        "        \"If the user's question asks for ONE attribute among \"\n",
        "        \"[Market, Region, SubMarket, CivilSupplier, True Handover Status, CutoverDate, \"\n",
        "        \"SwapType, Completed, ClosedOut], respond with EXACTLY '<Attribute>: <value>' \"\n",
        "        \"and nothing else.\\n\\n\"\n",
        "\n",
        "        # Summary mode for everything else\n",
        "        \"Otherwise, write a concise narrative summary (3–6 sentences) that:\\n\"\n",
        "        \"• Summarizes ONLY these two comment fields when present:\\n\"\n",
        "        \"  - SSV Held Up Reasons – Ericsson RF ( More Details)\\n\"\n",
        "        \"  - Turf Vendor Additional Description/Comments\\n\"\n",
        "        \"If both comment fields are missing, add one sentence: 'No detailed reasons/comments provided.' \"\n",
        "        \"Do NOT use bullet points or tables.\"\n",
        "    )\n",
        "    return ChatPromptTemplate.from_messages([\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"Question: {question}\\n\\nContext:\\n{context}\")\n",
        "    ])\n",
        "\n",
        "qa_prompt = build_flexible_prompt()\n",
        "\n",
        "# Keep numeric IDs intact during follow-ups\n",
        "CONDENSE_PROMPT = PromptTemplate.from_template(\n",
        "    \"Rewrite the user's follow-up into a single, standalone search query. \"\n",
        "    \"PRESERVE any numeric identifiers exactly (e.g., USID, ID). \"\n",
        "    \"Don't answer the question; only rewrite it. Keep it brief and keyword-rich. \"\n",
        "    \"If the follow-up refers to 'this/that site', infer the USID/ID from the chat history if present.\\n\\n\"\n",
        "    \"Chat history:\\n{chat_history}\\n\\n\"\n",
        "    \"Follow-up question: {question}\\n\\n\"\n",
        "    \"Standalone query:\"\n",
        ")\n",
        "\n",
        "# 4.4 A) Stateless RAG (strictly grounded to retrieved chunks)\n",
        "stateless_qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    retriever=retriever,               # from Step 3\n",
        "    chain_type=\"stuff\",\n",
        "    chain_type_kwargs={\"prompt\": qa_prompt},\n",
        "    return_source_documents=True\n",
        ")\n",
        "\n",
        "def ask_once(question: str, k: int = 8):\n",
        "    flt = _build_filter_from_question(question)\n",
        "    prev_kwargs = dict(stateless_qa.retriever.search_kwargs)  # save\n",
        "    try:\n",
        "        new_kwargs = {\"k\": k}\n",
        "        if flt: new_kwargs[\"filter\"] = flt\n",
        "        stateless_qa.retriever.search_kwargs.update(new_kwargs)\n",
        "        out = stateless_qa.invoke({\"query\": question})\n",
        "        answer  = out[\"result\"]\n",
        "        sources = out.get(\"source_documents\", [])\n",
        "    finally:\n",
        "        stateless_qa.retriever.search_kwargs = prev_kwargs  # restore\n",
        "\n",
        "    print(\"🧠 Answer:\\n\", answer, \"\\n\")\n",
        "    print(\"📚 Sources:\")\n",
        "    for i, d in enumerate(sources[:5], 1):\n",
        "        preview = d.page_content[:200] + (\"...\" if len(d.page_content) > 200 else \"\")\n",
        "        print(f\"[{i}] {d.metadata} -> {preview}\")\n",
        "    return answer, sources\n",
        "\n",
        "# 4.5 B) Conversational RAG (memory fixed with output_key/input_key)\n",
        "memory = ConversationBufferMemory(\n",
        "    memory_key=\"chat_history\",\n",
        "    input_key=\"question\",     # what the chain expects as input\n",
        "    output_key=\"answer\",      # which output to store in memory\n",
        "    return_messages=True\n",
        ")\n",
        "\n",
        "# Use the SAME flexible prompt + the condense prompt inside the conversational chain\n",
        "conv_chain = ConversationalRetrievalChain.from_llm(\n",
        "    llm=llm,\n",
        "    retriever=retriever,\n",
        "    memory=memory,\n",
        "    return_source_documents=True,\n",
        "    condense_question_prompt=CONDENSE_PROMPT,\n",
        "    combine_docs_chain_kwargs={\"prompt\": qa_prompt},\n",
        ")\n",
        "\n",
        "def chat_once(question: str, k: int = 8):\n",
        "    flt = _build_filter_from_question(question)\n",
        "    prev_kwargs = dict(conv_chain.retriever.search_kwargs)  # save\n",
        "    try:\n",
        "        new_kwargs = {\"k\": k}\n",
        "        if flt: new_kwargs[\"filter\"] = flt\n",
        "        conv_chain.retriever.search_kwargs.update(new_kwargs)\n",
        "        out = conv_chain.invoke({\"question\": question})\n",
        "        answer  = out[\"answer\"]\n",
        "        sources = out.get(\"source_documents\", [])\n",
        "    finally:\n",
        "        conv_chain.retriever.search_kwargs = prev_kwargs  # restore\n",
        "\n",
        "    print(\"💬 Chat Answer:\\n\", answer, \"\\n\")\n",
        "    print(\"📚 Sources:\")\n",
        "    for i, d in enumerate(sources[:5], 1):\n",
        "        preview = d.page_content[:200] + (\"...\" if len(d.page_content) > 200 else \"\")\n",
        "        print(f\"[{i}] {d.metadata} -> {preview}\")\n",
        "    return answer, sources\n",
        "\n",
        "# 4.6 Quick smoke tests\n",
        "print(\"— Stateless QA —\")\n",
        "_ = ask_once(\"What market is USID 59919 in?\", k=8)          # should return one-liner\n",
        "_ = ask_once(\"Summarize USID 59919.\", k=12)                 # should return narrative\n",
        "\n",
        "print(\"\\n— Conversational QA —\")\n",
        "_ = chat_once(\"Tell me about 59919.\", k=8)                  # narrative\n",
        "_ = chat_once(\"And what's the market?\", k=8)                # one-liner via flexible prompt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwPYoNhd84Ef",
        "outputId": "c33ef442-a318-433d-b4d5-5f97e6883cd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1698312562.py:28: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  llm = ChatOpenAI(model=LLM_MODEL, temperature=0)\n",
            "/tmp/ipython-input-1698312562.py:113: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "— Stateless QA —\n",
            "🧠 Answer:\n",
            " Market: PACIFIC NORTHWEST \n",
            "\n",
            "📚 Sources:\n",
            "[1] {'CivilSupplier': 'MasTec', 'ID': '12011', 'True Handover Status': 'Pending Handover > 5 Days', 'ClosedOut': 'Pending', 'SSV Hold ( Removal) Date': '', 'SwapType': 'Warm', 'Market': 'PACIFIC NORTHWEST', 'CutoverDate': '2025-07-29 00:00:00', '__sheet': 'Sheet1', 'Region': 'WEST', 'Usid': '59919', '__file': 'Combined_Violations.xlsx', 'Completed': 'True', '_doc_id': '59919', 'Quad': '1', '_chunk_id': 'whole', 'SubMarket': 'WASHINGTON'} -> ## Keys\n",
            "Usid: 59919 | ID: 12011 | Region: WEST | Market: PACIFIC NORTHWEST | SubMarket: WASHINGTON | True Handover Status: Pending Handover > 5 Days | CutoverDate: 2025-07-29 00:00:00 | CivilSupplier:...\n",
            "🧠 Answer:\n",
            " The project associated with USID 59919 is experiencing delays due to issues with RET connections, as noted in the comments. The Turf Vendor has indicated that troubleshooting is in progress, with a forecasted resolution date of August 8. No additional detailed reasons or comments are provided. \n",
            "\n",
            "📚 Sources:\n",
            "[1] {'ClosedOut': 'Pending', 'SubMarket': 'WASHINGTON', 'CutoverDate': '2025-07-29 00:00:00', 'ID': '12011', 'True Handover Status': 'Pending Handover > 5 Days', 'Market': 'PACIFIC NORTHWEST', 'CivilSupplier': 'MasTec', '_doc_id': '59919', '__file': 'Combined_Violations.xlsx', '_chunk_id': 'whole', 'Usid': '59919', '__sheet': 'Sheet1', 'SwapType': 'Warm', 'Region': 'WEST', 'Completed': 'True', 'Quad': '1', 'SSV Hold ( Removal) Date': ''} -> ## Keys\n",
            "Usid: 59919 | ID: 12011 | Region: WEST | Market: PACIFIC NORTHWEST | SubMarket: WASHINGTON | True Handover Status: Pending Handover > 5 Days | CutoverDate: 2025-07-29 00:00:00 | CivilSupplier:...\n",
            "\n",
            "— Conversational QA —\n",
            "💬 Chat Answer:\n",
            " The project with USID 59919 is experiencing a delay in the handover process, which has been pending for more than five days. The cutover date is set for July 29, 2025, and the swap type is classified as \"Warm.\" The civil supplier involved is MasTec. Although the project is marked as completed, it has not yet been closed out. The comments indicate that as of August 6, troubleshooting is in progress with a forecasted resolution by August 8, and there are issues related to PIM and RET connections. Additionally, a RET issue is noted as a reason for the pending handover. \n",
            "\n",
            "📚 Sources:\n",
            "[1] {'_chunk_id': 'whole', 'True Handover Status': 'Pending Handover > 5 Days', 'Usid': '59919', 'SubMarket': 'WASHINGTON', 'CivilSupplier': 'MasTec', 'Completed': 'True', '_doc_id': '59919', 'Market': 'PACIFIC NORTHWEST', '__sheet': 'Sheet1', 'ID': '12011', 'CutoverDate': '2025-07-29 00:00:00', 'ClosedOut': 'Pending', '__file': 'Combined_Violations.xlsx', 'SSV Hold ( Removal) Date': '', 'Region': 'WEST', 'SwapType': 'Warm', 'Quad': '1'} -> ## Keys\n",
            "Usid: 59919 | ID: 12011 | Region: WEST | Market: PACIFIC NORTHWEST | SubMarket: WASHINGTON | True Handover Status: Pending Handover > 5 Days | CutoverDate: 2025-07-29 00:00:00 | CivilSupplier:...\n",
            "💬 Chat Answer:\n",
            " I don't know based on the provided context. \n",
            "\n",
            "📚 Sources:\n",
            "[1] {'Quad': '3', 'Completed': 'False', '__file': 'Combined_Violations.xlsx', '_chunk_id': 'whole', '_doc_id': '199309', 'True Handover Status': '', 'Market': 'E. PA/S. NJ/DE', 'Region': 'EAST', 'ClosedOut': '', 'CivilSupplier': 'Ericsson', 'CutoverDate': '2025-08-15 00:00:00', 'SubMarket': 'HARLY', 'SSV Hold ( Removal) Date': '', 'Usid': '199309', 'ID': '5909', '__sheet': 'Sheet1', 'SwapType': 'Cold'} -> ## Keys\n",
            "Usid: 199309 | ID: 5909 | Region: EAST | Market: E. PA/S. NJ/DE | SubMarket: HARLY | CutoverDate: 2025-08-15 00:00:00 | CivilSupplier: Ericsson | SwapType: Cold | Completed: False\n",
            "\n",
            "## Notes\n",
            "(N...\n",
            "[2] {'CutoverDate': '2025-08-15 00:00:00', 'SwapType': 'Warm', '_chunk_id': 'whole', 'True Handover Status': '', '__file': 'Combined_Violations.xlsx', 'SubMarket': 'SOUTHERN OH', 'Market': 'MICHIGAN/INDIANA/OHIO', 'Quad': '1', 'CivilSupplier': 'Ericsson', 'ClosedOut': '', 'Completed': 'False', 'SSV Hold ( Removal) Date': '', 'ID': '10812', '_doc_id': '60146', 'Usid': '60146', '__sheet': 'Sheet1', 'Region': 'EAST'} -> ## Keys\n",
            "Usid: 60146 | ID: 10812 | Region: EAST | Market: MICHIGAN/INDIANA/OHIO | SubMarket: SOUTHERN OH | CutoverDate: 2025-08-15 00:00:00 | CivilSupplier: Ericsson | SwapType: Warm | Completed: False...\n",
            "[3] {'Quad': '1', 'Usid': '5568', 'ID': '10901', '__sheet': 'Sheet1', 'Market': 'NY/NNJ', 'Region': 'EAST', 'True Handover Status': '', 'CutoverDate': '2025-08-15 00:00:00', 'CivilSupplier': 'Ericsson', '_chunk_id': 'whole', 'Completed': 'False', '__file': 'Combined_Violations.xlsx', 'ClosedOut': '', 'SSV Hold ( Removal) Date': '', '_doc_id': '5568', 'SubMarket': 'NYC EAST', 'SwapType': 'Warm'} -> ## Keys\n",
            "Usid: 5568 | ID: 10901 | Region: EAST | Market: NY/NNJ | SubMarket: NYC EAST | CutoverDate: 2025-08-15 00:00:00 | CivilSupplier: Ericsson | SwapType: Warm | Completed: False\n",
            "\n",
            "## Notes\n",
            "(No deta...\n",
            "[4] {'Completed': 'False', 'ID': '12830', '__file': 'Combined_Violations.xlsx', 'Usid': '431', 'Region': 'EAST', '__sheet': 'Sheet1', '_chunk_id': 'whole', 'SwapType': 'Warm', 'Quad': '1', 'ClosedOut': '', 'SubMarket': 'OUTSTATE MI', 'True Handover Status': '', 'CivilSupplier': 'Ericsson', 'Market': 'MICHIGAN/INDIANA/OHIO', '_doc_id': '431', 'CutoverDate': '2025-08-15 00:00:00', 'SSV Hold ( Removal) Date': ''} -> ## Keys\n",
            "Usid: 431 | ID: 12830 | Region: EAST | Market: MICHIGAN/INDIANA/OHIO | SubMarket: OUTSTATE MI | CutoverDate: 2025-08-15 00:00:00 | CivilSupplier: Ericsson | SwapType: Warm | Completed: False\n",
            "\n",
            "...\n",
            "[5] {'CivilSupplier': 'Ericsson', '__sheet': 'Sheet1', '__file': 'Combined_Violations.xlsx', 'SubMarket': 'NORTHERN OH', 'Usid': '259200', '_chunk_id': 'whole', 'CutoverDate': '2025-08-15 00:00:00', 'Market': 'MICHIGAN/INDIANA/OHIO', 'True Handover Status': '', 'Region': 'EAST', 'ID': '11772', 'ClosedOut': '', 'Quad': '3', 'SSV Hold ( Removal) Date': '', 'SwapType': 'Cold', 'Completed': 'False', '_doc_id': '259200'} -> ## Keys\n",
            "Usid: 259200 | ID: 11772 | Region: EAST | Market: MICHIGAN/INDIANA/OHIO | SubMarket: NORTHERN OH | CutoverDate: 2025-08-15 00:00:00 | CivilSupplier: Ericsson | SwapType: Cold | Completed: Fals...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Do NOT include \"ids\" in include=\n",
        "res = chroma_vs._collection.get(\n",
        "    where={\"Usid\": \"50539\"},\n",
        "    include=[\"metadatas\", \"documents\"]  # ids are returned automatically\n",
        ")\n",
        "print(\"In Chroma:\", len(res.get(\"ids\", [])))\n",
        "if res.get(\"ids\"):\n",
        "    print(\"ID:\", res[\"ids\"][0])\n",
        "    print(\"Metadata:\", res[\"metadatas\"][0])\n",
        "    print(\"Doc preview:\", res[\"documents\"][0][:300])\n",
        "else:\n",
        "    print(\"USID 50539 is NOT in the vector store (likely filtered out in Step 2.10).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnajlkdajWCJ",
        "outputId": "08ca9fa5-c4b9-42b0-dd75-af3c4d454e3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In Chroma: 1\n",
            "ID: 97237893-06b9-4868-88fe-bc28f4895052\n",
            "Metadata: {'_chunk_id': 'whole', 'ID': '11914', '__sheet': 'Sheet1', 'CutoverDate': '2025-07-26 00:00:00', '_doc_id': '50539', 'Region': 'WEST', 'Usid': '50539', 'Completed': 'True', 'Market': 'SOUTHWEST STATES', 'True Handover Status': 'Handed Over', 'Quad': '1', 'ClosedOut': 'Pending', 'CivilSupplier': 'MasTec', '__file': 'Combined_Violations.xlsx', 'SubMarket': 'LAS VEGAS', 'SSV Hold ( Removal) Date': '2025-08-11 00:00:00', 'SwapType': 'Warm'}\n",
            "Doc preview: ## Keys\n",
            "Usid: 50539 | ID: 11914 | Region: WEST | Market: SOUTHWEST STATES | SubMarket: LAS VEGAS | True Handover Status: Handed Over | CutoverDate: 2025-07-26 00:00:00 | CivilSupplier: MasTec | SwapType: Warm | Completed: True | ClosedOut: Pending\n",
            "\n",
            "## Turf Vendor Additional Description/Comments\n",
            "08/0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# STEP 5 — Gradio ChatInterface (conversational, memory, small-talk, number normalization)\n",
        "# =========================\n",
        "# If needed: %pip -q install gradio\n",
        "\n",
        "import re\n",
        "import gradio as gr\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "\n",
        "# 1) One global chain with memory (reuse llm, retriever, qa_prompt, CONDENSE_PROMPT from Step 4)\n",
        "memory = ConversationBufferMemory(\n",
        "    memory_key=\"chat_history\",\n",
        "    input_key=\"question\",\n",
        "    output_key=\"answer\",\n",
        "    return_messages=True,\n",
        ")\n",
        "\n",
        "conversation_chain = ConversationalRetrievalChain.from_llm(\n",
        "    llm=llm,\n",
        "    retriever=retriever,\n",
        "    memory=memory,\n",
        "    return_source_documents=True,\n",
        "    condense_question_prompt=CONDENSE_PROMPT,          # keep numeric IDs intact\n",
        "    combine_docs_chain_kwargs={\"prompt\": qa_prompt},   # your flexible one-liner/summary prompt\n",
        ")\n",
        "\n",
        "# 2) Track last active row filter (USID/ID) across turns\n",
        "LAST_FILTER = {}  # e.g., {\"Usid\": \"111732\"} or {\"ID\": \"10517\"}\n",
        "\n",
        "def _iter_user_text(history):\n",
        "    \"\"\"Yield user texts from Gradio ChatInterface history (supports tuples or dict messages).\"\"\"\n",
        "    for item in history or []:\n",
        "        if isinstance(item, dict):\n",
        "            if item.get(\"role\") == \"user\":\n",
        "                yield item.get(\"content\", \"\")\n",
        "        else:\n",
        "            if isinstance(item, (list, tuple)) and len(item) >= 1:\n",
        "                yield item[0] or \"\"\n",
        "\n",
        "def _update_active_filter(msg: str, history):\n",
        "    \"\"\"Return the best filter for this turn; update LAST_FILTER when we find one.\"\"\"\n",
        "    if '_build_filter_from_question' in globals():\n",
        "        f = _build_filter_from_question(msg)\n",
        "        if f:\n",
        "            LAST_FILTER.clear(); LAST_FILTER.update(f)\n",
        "            return f\n",
        "    try:\n",
        "        for text in reversed(list(_iter_user_text(history))):\n",
        "            if '_build_filter_from_question' in globals():\n",
        "                f2 = _build_filter_from_question(text)\n",
        "                if f2:\n",
        "                    LAST_FILTER.clear(); LAST_FILTER.update(f2)\n",
        "                    return f2\n",
        "    except Exception:\n",
        "        pass\n",
        "    return LAST_FILTER or None\n",
        "\n",
        "# 3) Small-talk detection & replies\n",
        "_SMALL_GREET = re.compile(\n",
        "    r\"\\b(hi|hello|hey|good\\s*(morning|afternoon|evening)|how\\s*are\\s*you|how'?s\\s*it\\s*going|what'?s\\s*up)\\b\",\n",
        "    re.IGNORECASE,\n",
        ")\n",
        "_SMALL_THANKS = re.compile(r\"\\b(thanks|thank\\s*you|thx|much\\s*appreciated)\\b\", re.IGNORECASE)\n",
        "_SMALL_ACK = re.compile(r\"^\\s*(ok(ay)?|cool|great|awesome|nice|got\\s*it|understood|roger|y(ep|up)|sure)\\s*[.!]?\\s*$\", re.IGNORECASE)\n",
        "_SMALL_BYE = re.compile(r\"\\b(bye|good\\s*night|good\\s*bye|see\\s*(ya|you))\\b\", re.IGNORECASE)\n",
        "\n",
        "def _looks_like_query(s: str) -> bool:\n",
        "    s = s.lower()\n",
        "    if re.search(r\"\\d{3,}\", s):\n",
        "        return True\n",
        "    for kw in [\"usid\", \"id \", \"market\", \"region\", \"submarket\", \"civil\", \"handover\", \"cutover\",\n",
        "               \"swap\", \"rf\", \"ssv\", \"ericsson\", \"vendor\", \"comments\", \"reasons\", \"status\"]:\n",
        "        if kw in s:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def _smalltalk_kind(msg: str) -> str | None:\n",
        "    s = (msg or \"\").strip()\n",
        "    if not s or _looks_like_query(s):\n",
        "        return None\n",
        "    if _SMALL_THANKS.search(s): return \"thanks\"\n",
        "    if _SMALL_BYE.search(s):    return \"bye\"\n",
        "    if _SMALL_GREET.search(s):  return \"greet\"\n",
        "    if _SMALL_ACK.search(s):    return \"ack\"\n",
        "    return None\n",
        "\n",
        "def _smalltalk_reply(kind: str) -> str:\n",
        "    if kind == \"thanks\":\n",
        "        return (\"You're welcome! If you'd like, ask for a summary for a USID \"\n",
        "                \"(e.g., 'Summarize 111732') or a quick field like 'What market is 111732 in?'\")\n",
        "    if kind == \"bye\":\n",
        "        return \"Take care! Ping me anytime if you need another site summary.\"\n",
        "    if kind == \"greet\":\n",
        "        return (\"Hi! I can summarize a site (e.g., 'Summarize 111732') or answer quick lookups \"\n",
        "                \"like 'Who is the civil supplier for 111732?'. I’ll remember context.\")\n",
        "    if kind == \"ack\":\n",
        "        return \"👍 Got it. Ask me about another USID or a specific field when you're ready.\"\n",
        "    return \"How can I help next?\"\n",
        "\n",
        "# 4) Bare-number normalization (e.g., \"11386\" → \"Summarize USID 11386\")\n",
        "_NUM_ONLY = re.compile(r\"^\\s*(\\d{3,})\\s*$\")\n",
        "def _normalize_message(msg: str) -> str:\n",
        "    m = _NUM_ONLY.match(msg or \"\")\n",
        "    if m:\n",
        "        return f\"Summarize USID {m.group(1)}\"\n",
        "    return msg\n",
        "\n",
        "FALLBACK_LINE = \"I don't know based on the provided context.\"\n",
        "\n",
        "# 5) Chat handler: small talk, normalization, reuse active filter, retry if needed\n",
        "def chat(message, history):\n",
        "    msg = (message or \"\").strip()\n",
        "    if not msg:\n",
        "        return \"_Please enter a question_\"\n",
        "\n",
        "    # Small talk bypasses RAG\n",
        "    kind = _smalltalk_kind(msg)\n",
        "    if kind:\n",
        "        return _smalltalk_reply(kind)\n",
        "\n",
        "    # Normalize bare numbers to a clear intent\n",
        "    msg = _normalize_message(msg)\n",
        "\n",
        "    # Anchor retrieval to the current/last USID/ID\n",
        "    flt = _update_active_filter(msg, history)\n",
        "\n",
        "    prev_kwargs = dict(conversation_chain.retriever.search_kwargs)\n",
        "    try:\n",
        "        kwargs = {\"k\": 8}\n",
        "        if flt:\n",
        "            kwargs[\"filter\"] = flt\n",
        "        conversation_chain.retriever.search_kwargs.update(kwargs)\n",
        "\n",
        "        out = conversation_chain.invoke({\"question\": msg})\n",
        "        ans = out.get(\"answer\", \"\")\n",
        "\n",
        "        # If we got the strict fallback but have a target USID/ID, retry with a stronger cue\n",
        "        if ans.strip() == FALLBACK_LINE and flt:\n",
        "            target = flt.get(\"Usid\") or flt.get(\"ID\") or \"\"\n",
        "            if target:\n",
        "                retry_q = f\"Provide a concise narrative summary for USID {target} based strictly on the context.\"\n",
        "                out = conversation_chain.invoke({\"question\": retry_q})\n",
        "                ans = out.get(\"answer\", \"\") or ans\n",
        "\n",
        "        return ans\n",
        "    except Exception as e:\n",
        "        return f\"_Error: {e}_\"\n",
        "    finally:\n",
        "        conversation_chain.retriever.search_kwargs = prev_kwargs\n",
        "\n",
        "# 6) UI\n",
        "examples = [\n",
        "    \"Tell me about USID 95149\",\n",
        "    \"11386\",\n",
        "    \"Who is the civil supplier?\",\n",
        "    \"Any Ericsson RF details or civil comments?\",\n",
        "]\n",
        "\n",
        "chatbot = gr.Chatbot(show_copy_button=True)\n",
        "\n",
        "try:\n",
        "    demo = gr.ChatInterface(\n",
        "        fn=chat,\n",
        "        chatbot=chatbot,\n",
        "        title=\"AT&T Allagi Deployment — Conversational AI\",\n",
        "        description=\"Ask about USIDs, markets, suppliers, handover status. I remember context within this chat.\",\n",
        "        examples=examples,\n",
        "        type=\"messages\",\n",
        "    )\n",
        "except TypeError:\n",
        "    demo = gr.ChatInterface(\n",
        "        fn=chat,\n",
        "        chatbot=chatbot,\n",
        "        title=\"AT&T Allagi Deployment — Conversational AI\",\n",
        "        description=\"Ask about USIDs, markets, suppliers, handover status. I remember context within this chat.\",\n",
        "        examples=examples,\n",
        "    )\n",
        "\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "jeEeNvVoloHa",
        "outputId": "b08e33f5-a26e-4335-e5a3-bc8bd984b0b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3745682891.py:160: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot(show_copy_button=True)\n",
            "/usr/local/lib/python3.11/dist-packages/gradio/chat_interface.py:321: UserWarning: The type of the gr.Chatbot does not match the type of the gr.ChatInterface.The type of the gr.ChatInterface, 'messages', will be used.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://11f0d3db3be36655b3.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://11f0d3db3be36655b3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}